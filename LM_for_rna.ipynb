{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81feac78",
   "metadata": {
    "cellId": "bnn7relguhpz8kke0p1b"
   },
   "source": [
    "### Language models for rna sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e5dba86",
   "metadata": {
    "cellId": "cl66kfdrbmle1sozi5eqwr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605fc29f",
   "metadata": {
    "cellId": "nvgkfykqs6kdjubmq5c9if"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "EOS = '\\n'\n",
    "BOS = ' '\n",
    "UNK = '_'\n",
    "\n",
    "token_to_id = {BOS: 0, EOS: 1, UNK: 2, 'a': 10, 'c': 11, 'g': 12, 'u': 13}\n",
    "id_to_token = {v: k for k, v in token2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7f9cb9d",
   "metadata": {
    "cellId": "bvn99cyiboaacun0bevpt"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def to_matrix(lines, max_len=None, pad=token_to_id[EOS], unk=token_to_id[UNK], dtype=np.int64):\n",
    "    \"\"\"\n",
    "    Casts a list of lines into torch-digestable matrix\n",
    "    \"\"\"\n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    n_lines = len(lines)\n",
    "    matrix = np.full([n_lines, max(map(len, lines))], pad, dtype=dtype)\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        line_tokenized = [token_to_id.get(c, unk) for c in line[:max_len]]\n",
    "        matrix[i, :len(line_tokenized)] = line_tokenized\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0b8c444",
   "metadata": {
    "cellId": "r0bve1897bojw2tck1rbs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 11, 13,  2,  1,  1,  1,  1,  1,  1],\n",
       "       [10, 11, 12, 10, 11, 13, 11, 13, 13, 12]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "seqs = ['acut', 'acgacucuug']\n",
    "to_matrix(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c0f3984",
   "metadata": {
    "cellId": "zta95ocxao71flclczv9g"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def compute_mask(matrix, eos=token_to_id[EOS]):\n",
    "    \"\"\"\n",
    "    compute a boolean mask that equals \"1\" until first EOS (including that EOS) \n",
    "    \"\"\"\n",
    "    return F.pad(torch.cumsum(matrix == eos, dim=-1)[..., :-1] < 1, pad=(1, 0, 0, 0), value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8318cd08",
   "metadata": {
    "cellId": "a968htmh92kva149cgv6gi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "compute_mask(torch.tensor(to_matrix(seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab076c97",
   "metadata": {
    "cellId": "8ozsldxxgs9055h3le6sny2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def compute_loss(model, matrix):\n",
    "    \"\"\"\n",
    "    :param model: language model that can compute next token logits given token indices\n",
    "    :param matrix: int32 matrix of tokens, shape: [batch_size, length]; padded with eos_ix\n",
    "    :returns: scalar loss function, mean crossentropy over non-eos tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    matrix = torch.as_tensor(matrix, dtype=torch.int64).to(model.device)\n",
    "\n",
    "    logits = model(matrix[:, :-1])\n",
    "    reference_answers = matrix[:, 1:].detach()\n",
    "    \n",
    "    batch_size = matrix.shape[0]\n",
    "\n",
    "    loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    mask = compute_mask(reference_answers).to(torch.int32).detach()\n",
    "    \n",
    "    out = torch.sum(loss(logits.permute(0, 2, 1), reference_answers) * mask) / mask.sum()\n",
    "\n",
    "    return out \n",
    "\n",
    "\n",
    "def score_lines(model, lines, batch_size):\n",
    "    \"\"\"\n",
    "    computes average loss over the entire dataset\n",
    "    \"\"\"\n",
    "    loss_num = 0.\n",
    "    loss_len = 0.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(lines), batch_size):\n",
    "            batch = to_matrix(lines[i: i + batch_size])\n",
    "            loss_num += compute_loss(model, batch).item() * len(batch)\n",
    "            loss_len += len(batch)\n",
    "    return loss_num / loss_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4ceb9a9",
   "metadata": {
    "cellId": "fxaypyapqqbxut4wuttljj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_model(model, optimizer, val_lines, batch_size, scheduler=None):\n",
    "    train_loss = []\n",
    "    model.train(True) \n",
    "    for i in range(0, len(val_lines), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = to_matrix(val_lines[i: i + batch_size])\n",
    "        loss = compute_loss(model, batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def train(model, optimizer, train_lines, val_lines, num_epochs, batch_size, scheduler=None):\n",
    "    train_history = []\n",
    "    test_history = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss = train_model(model, optimizer, train_lines, batch_size, scheduler)\n",
    "        train_history.append((epoch + 1, train_loss))\n",
    "\n",
    "        test_history.append((epoch + 1, score_lines(model, val_lines, batch_size)))\n",
    "\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(*zip(*train_history), color='blue', label='train_loss')\n",
    "        plt.plot(*zip(*test_history), color='red', label='dev_loss')\n",
    "        plt.legend(); plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}min\".format(epoch + 1, num_epochs, (time.time() - start_time) / 60))\n",
    "        print(\"  training loss (in-iteration): {}\".format(train_history[-5:]))\n",
    "        print(\"  validation loss (in-iteration): {}\".format(test_history[-5:]))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "351f428c",
   "metadata": {
    "cellId": "7zauqjnws4wuiv5vo5j468"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class FixedWindowLanguageModel(nn.Module):\n",
    "    def __init__(self, n_tokens=len(token_to_id), emb_size=16, hid_size=64, window_size=5):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.emb = nn.Embedding(n_tokens, emb_size)\n",
    "        self.pad = nn.ZeroPad2d((self.window_size - 1, 0, 0, 0))\n",
    "        self.conv = nn.Conv1d(emb_size, hid_size, kernel_size=self.window_size)\n",
    "        self.fc = nn.Linear(hid_size, n_tokens)\n",
    "            \n",
    "    def __call__(self, input_ix):\n",
    "\n",
    "        out = self.emb(input_ix).permute((0, 2, 1))\n",
    "        out = self.pad(out)\n",
    "        out = self.conv(out).permute((0, 2, 1))\n",
    "        \n",
    "        return self.fc(out) # [batch_size, sequence_length, n_tokens]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a18fe2d",
   "metadata": {
    "cellId": "4z96ml43m2ibte97var5y5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, n_tokens=n_tokens, emb_size=16, hid_size=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(n_tokens, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hid_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_size, n_tokens)\n",
    "        \n",
    "        #END OF YOUR CODE\n",
    "    \n",
    "    def __call__(self, input_ix):\n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "        \n",
    "        x = self.emb(input_ix)\n",
    "        states, _ = self.lstm(x)\n",
    "\n",
    "        out = self.fc(states)\n",
    "        \n",
    "        return out #[batch_size, sequence_length, n_tokens]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e946d8",
   "metadata": {
    "cellId": "qn3ujx0xrm76ukukf1com"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "c697a41b-2a79-463e-a5ab-f59e8616eb86",
  "notebookPath": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
